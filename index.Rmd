---
title: 'Construction and leverage scientific knowledge graphs by means of semantic technologies'
mainfont: Times New Roman
author: "Janneth Chicaiza, Mariela Tapia-Leon and Teresa Santamaria-Leon"
date: "May 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    includes:
      in_header: header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
font-family: Times New Roman
link-citations: yes
csl: apa.csl
bibliography: scholar.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r load_libraries, include=FALSE}
#library(XML)
library(SPARQL) # SPARQL querying package
library(ggplot2)
library(ggraph)
library(igraph)
library(tidyverse)
library(RColorBrewer) 
library(colormap)
library(kableExtra)
library(knitr)
library(wordcloud2)
library(quanteda)
library(slam)
library(tm)
library(SemNetCleaner)
library(textstem)
set.seed(1)
```

******
# Introduction
******
## Description

Some institutions measure the quality of a university according their scientific production. Currently, many universities register their scientific production in open access repositories. Also, scientific production is available in different scientific databases (Scopus, Web of Science). Connecting these data, with the application of ontologies, will potentially increase their value and help discover interesting relationships amongst them. This article explains what extent SPAR Ontology Network allowed to represent semantically the scientific production generated in a university and proposes an extension to cover the terms that SPAR Ontology did not have. For that, we worked with datasets obtained from Scopus about the contributions published by the University of Guayaquil and transformed it to RDF using the SPAR Ontology Network. We identified a small set of terms and relationships to add to BiDo Ontology (part of SPAR Ontology Network).  We created and validated our extension ontology propose using competency questions whose results were plotted through R language.

## Background

This technical report is based on the implementation of previous studies. The first one was named "Using the SPAR Ontology Network to represent the Scientific Production of a University: A Case Study" [@Tapia2019a] and the second one was named "Extension of the BiDO Ontology to Represent Scientific Production" [@Tapia2019b]. Besides, we have added a graphic representation using R language that allows transforms the SPARQL query results into statistics charts


******
# Functional requirements
******

## Competency and SPARQL Queries

Part of the competency questions are based on the criteria "Scientific Production" of the "Model Generic of Evaluation of the Environment of Learning of Careers in Ecuador" by CACES  â€“ Ecuador(CACES, 2017). The competency questions implemented as SPARQL queries were:

* Query 1: What type of document is published by UG researchers and what is its impact according to the source where they publish?

$$
# SPARQL Query:
PREFIX bido: <http://purl.org/spar/bido-core/>
PREFIX frbr: <http://purl.org/vocab/frbr/core/>
PREFIX spar: <http://purl.org/spar/bido/>
SELECT DISTINCT ?pubType, SUM(IF(?rank <= 10, 1, 0)) AS ?rank10, 
   SUM(IF(?rank > 10 && ?rank <= 50, 1, 0)) AS ?rank11_50,
   SUM(IF(?rank > 50 && ?rank <= 100, 1, 0)) AS ?rank51_100,
   SUM(IF(?rank > 100 && ?rank <= 500, 1, 0)) AS ?rank101_500,
   SUM(IF(?rank > 500, 1, 0)) AS ?rankMore500
FROM <http://spar.linkeddata.es/graph/bido>
WHERE{ ?paper a ?type ; frbr:partOf ?source. 
   BIND(REPLACE(STR(?type), 'http://purl.org/spar/fabio/', '') AS ?pubType)
   FILTER (?pubType != "Expression")
   { SELECT ?paper, MIN(?rankA) as ?rank
    WHERE {
       ?paper a ?type ; frbr:partOf ?source.
       ?source bido:holdsBibliometricDataInTime ?SMY.
       ?SMY bido:withBibliometricData/bido:rankInQuartile ?r .
       ?SMY bido:accordingTo [].
       BIND(xsd:integer(?r) AS ?rankA)
       BIND(REPLACE(STR(?type), 'http://purl.org/spar/fabio/', '') AS ?pubType)
       FILTER (?pubType != "Expression")
    } GROUP BY ?paper
  }
}
$$

* Query 2: What is the distribution of citations by papers?

$$
# SPARQL Query:
PREFIX bido: <http://purl.org/spar/bido-core/>
PREFIX fabio: <http://purl.org/spar/fabio/>
PREFIX frbr: <http://purl.org/vocab/frbr/core/>
PREFIX spar: <http://purl.org/spar/bido/>
SELECT DISTINCT ?numCites  (count(*) AS ?freq)
FROM <http://spar.linkeddata.es/graph/bido>
WHERE {  
  ?paper ^frbr:realization [];  bido:holdsBibliometricDataInTime ?paperMeasure .
  ?paperMeasure bido:withBibliometricData ?paperCitations .  
  ?paperCitations bido:hasMeasure spar:paper-citation-count ; bido:hasNumericValue ?numCites2.
  BIND(xsd:int(?numCites2) as ?numCites )
} ORDER BY ASC(?numCites)
$$

* Query 3: What are the most popular publication sources and what is their impact factor quartile?

$$
# SPARQL Query:
PREFIX foaf: <http://xmlns.com/foaf/0.1/>
PREFIX fabio: <http://purl.org/spar/fabio/>
PREFIX frbr: <http://purl.org/vocab/frbr/core/>
PREFIX bido: <http://purl.org/spar/bido-core/>
SELECT ?journal ?bQuartile (count(*) AS ?number)
FROM <http://spar.linkeddata.es/graph/bido>
WHERE {
   ?source ^frbr:partOf []; rdf:type fabio:Journal ; foaf:name ?name .
   BIND(replace(UCASE(?name), '\\.', '') AS ?journal)
   { SELECT ?source min(?quartile) as ?bQuartile 
     WHERE { 
       ?source bido:holdsBibliometricDataInTime/bido:withBibliometricData/bido:hasQuartile ?q .   
       BIND(REPLACE(STR(?q), 'http://purl.org/spar/bido/Q', '') AS ?quartile)
     }
    }
} 
$$

* Query 4: Who are the researchers working in the disciplines of a specific area and what is their production

$$
# SPARQL Query:
PREFIX bido: <http://purl.org/spar/bido-core/>
PREFIX frbr: <http://purl.org/vocab/frbr/core/>
PREFIX dcterms: <http://purl.org/dc/terms/>
SELECT DISTINCT ?root_name ?parent_name ?child_name
FROM <http://spar.linkeddata.es/graph/bido>
WHERE{ VALUES ?area {<http://bido.linkeddata.es/ext/1200>}
    ?paper frbr:partOf ?source .
    ?author foaf:name ?child_name ;  dcterms:creator ?paper .
    ?source bido:holdsBibliometricDataInTime ?SMY .
    ?SMY bido:withBibliometricData ?SYAD .
    ?SYAD bido:relatesToSubjectCategory ?disc ;  bido:hasQuartile ?Q .
    ?disc skos:prefLabel ?parent_name ;  skos:broader ?area . 
    ?area skos:prefLabel ?root_name .
} ORDER BY ?root_name ?parent_name ?child_name
$$
* Query 5: What are the main interests of the UG researchers?

$$
# SPARQL Query:
PREFIX bido: <http://purl.org/spar/bido-core/>
PREFIX frbr: <http://purl.org/vocab/frbr/core/>
PREFIX spar: <http://purl.org/spar/bido/>
PREFIX dct: <http://purl.org/dc/terms/>
SELECT DISTINCT ?title ?date WHERE{
  ?paper a [] ; frbr:partOf [] .
  ?biblio frbr:realization ?paper .
  ?biblio dct:issued ?date ; dct:title ?title . 
} ORDER BY ?title
$$

## Configuration data:

To execute previous queries in a engine, next information can be used.

$SPARQL\ Endpoint:$ <http://spar.linkeddata.es/sparql>

$Graph\ name:$ <http://spar.linkeddata.es/graph/bido>

All queries are available in the csv file, queries.csv.


******
# Graphics  
******


```{r}
endpoint <- "http://spar.linkeddata.es/sparql"

# load templates of queries
queries <- read.csv("queries.csv" , header=F, sep=",")

```
## Query 1: What kind of publications are there?

According to the document type available in Scopus for UG publications, three of the four papers are published in journals (see next Figure). On the other hand, the least amount of publications corresponds to the book chapters

```{r message= FALSE, warning=FALSE}
query1 <- as.character(queries$V2[1])
qd1 <- SPARQL(endpoint, query1)
df1 <- qd1$results
df11 <- df1[, c("pubType", "rank10")]
names(df11) <- c("pubType", "freq")
df11['group'] <- 'Rank <= 10'
df12 <- df1[, c("pubType", "rank11_50")]
names(df12) <- c("pubType", "freq")
df12['group'] <- 'Rank 11-50'
df13 <- df1[, c("pubType", "rank51_100")]
names(df13) <- c("pubType", "freq")
df13['group'] <- 'Rank 51-100'
df14 <- df1[, c("pubType", "rank101_500")]
names(df14) <- c("pubType", "freq")
df14['group'] <- 'Rank 101-500'
df15 <- df1[, c("pubType", "rankMore500")]
names(df15) <- c("pubType", "freq")
df15['group'] <- 'Rank > 500'

df1 <- rbind(df11, df12, df13, df14, df15)
df1$pubType <- as.factor(df1$pubType) 
df1$group <- as.factor(df1$group) 
docType_tot = data.frame(aggregate(freq ~ pubType, df1, sum))
docType_tot <- docType_tot %>%
  mutate(prop = round(freq*100/sum(freq), 1),
         lab.ypos = (cumsum(prop) - 0.5*prop))
docType_tot <- docType_tot[, c('pubType', 'prop')]
df1 <- merge (df1, docType_tot, by = "pubType")
df1$prop <- as.character(df1$prop)
df1$pubType <- gsub(pattern = "\\s", replacement = "", x = paste(df1$pubType, ':', df1$prop, '%'))
colors <- c("#17B890", "#808080", "#C0C0C0", "#26817C", "#97D2E6") #   scale_fill_brewer() 
ggplot(data=df1, aes(x=pubType, y=freq)) +
  geom_bar(aes(fill = group), stat="identity", position="fill") + #position_dodge(width=0.9))+
  xlab("Document type") + ylab("Rank distribution") +
  labs(fill = 'Journals\' Rank ')+
  theme_classic() +
  scale_fill_manual(values=colors) +
  theme(text=element_text(family="Times New Roman", size=12)) +
  theme(legend.position="top", legend.box = "horizontal") 
  
```

## Query 2: What is the distribution of citations by papers?
```{r message= FALSE, warning=FALSE}

query2 <- as.character(queries$V2[2])
qd2 <- SPARQL(endpoint, query2)
df2 <- qd2$results

#Exploring outliers
head(arrange(df2, df2$numCites), 5) # 279 papers have never been cited
tail(arrange(df2, df2$numCites), 5) # some papers have at least 1 cite

#Extracting a subset without outliers
df2.subset <- subset(df2, numCites > 0 & numCites <=50)
par(family = "Times New Roman")
plot(df2.subset, type='o', bty="n", pch=20, cex=df2.subset$freq/2^2, col="#97D2E6", ylim=c(0, 55), xlim=c(0, 50), xlab="Number of cites", ylab="Number of Journals")
#text(df2.subset[,'freq'])

```

By removing outliers, i.e. papers without any citation (279) and papers with more than 50 citations, the previous figure shows the distribution resulting. Note that the number of papers decreases as the number of citations increases.

## Query 3: What are the most popular publication sources and what is their impact factor quartile?

```{r message= FALSE, warning=FALSE}
query3 <- as.character(queries$V2[3])
qd3 <- SPARQL(endpoint, query3)
df3 <- qd3$results
df3$bQuartile <- as.numeric(df3$bQuartile)
df3$journal <- substr(df3$journal, 1, 25)
# Filtering jounals with more than 3 publications
df3.subset <- subset(df3, number >3)
kable(df3.subset, caption="Jounals with more than 2 publications", format="markdown")
summary(df3.subset)
ggplot(data=df3.subset, aes(x=journal, y=number)) +
  geom_text(aes(label = number), vjust = -0.5, family="Times New Roman") +
  geom_bar(aes(fill = bQuartile), stat = "identity", width=0.6) + #width = 0.6) +
  geom_text(colour = "white", vjust = 1.3, size = 3.3, aes(label = paste0("Q", bQuartile)), family="Times New Roman") +
  ylim(0, 65)+ ylab("Papers")+
  xlab("Journals")+
  theme_classic() +
  theme(legend.position="none", text=element_text(family="Times New Roman", size=12)) +
  theme(axis.text.x = element_text(angle = 90, hjust=0.95,vjust=0.2, size=7.5))

```

As you can see, the "Espacios" journal is the source most chosen by UG researchers. Futhermore, there are other journals with 1 or 2 publications:

```{r message= FALSE, warning=FALSE}
print (sprintf("Journals with 1 papers is %i", NROW(subset(df3, number==1))))
print (sprintf("Journals with 2 papers is %i", NROW(subset(df3, number==2))))

```

These results make us suspect that the impact factor quartile is not one of the dominant criteria that researchers values when choosing the source to publish their research.


## Query 4: Who are the researchers working in the disciplines of a specific area and what is their production?

Here, we present a dendrogram of researchers grouped by topic. Each subtree shows people who have published in the same discipline. The color distinguishes the authors related to more than 1 topic. Graphics like this graphic can be very useful to find pairs of researchers in the same area.

```{r message= FALSE, warning=FALSE}
query4 <- as.character(queries$V2[4])
qd4 <- SPARQL(endpoint, query4)
df4 <- qd4$results

edgeL1 <- df4[, c("root_name", "parent_name")]
edgeL2 <- df4[, c("parent_name", "child_name")]
names(edgeL1) <- c("from", "to")
names(edgeL2) <- c("from", "to")
edgesQ4 <- rbind(edgeL1, edgeL2)
nameQ4 <- unique(c(as.character(edgesQ4$from), as.character(edgesQ4$to)))
len <- NROW(nameQ4)
verticesQ4 = data.frame(
  name = nameQ4 , 
  value = runif(len)
) 
verticesQ4$group = edgesQ4$from[ match( verticesQ4$name, edgesQ4$to ) ]
verticesQ4$id=NA
leavesQ4=which(is.na( match(verticesQ4$name, edgesQ4$from) ))
nleavesQ4=length(leavesQ4)
verticesQ4$id[ leavesQ4 ] = seq(1:nleavesQ4)
verticesQ4$angle= 90 - 360 * verticesQ4$id / nleavesQ4
verticesQ4$hjust<-ifelse( verticesQ4$angle < -90, 1, 0)
verticesQ4$angle<-ifelse(verticesQ4$angle < -90, verticesQ4$angle+180, verticesQ4$angle)
graphQ4 <- graph_from_data_frame( edgesQ4, vertices=verticesQ4 )
labels <- df4[, 2]
labels <- labels[!duplicated(labels)]
colors4 <- c("#1768AC", "#06BEE1", "#03256C", "#26817C", "#17B890", "#cc6633") 
p4 <- ggraph(graphQ4, layout = 'dendrogram', circular = TRUE) + 
  geom_edge_diagonal(colour="grey") +
  geom_node_text(aes(x = x*1.15, y=y*1.15, filter = leaf, label=name, angle = 90, hjust=hjust, colour=group), size=2.7, alpha=1, family="Times New Roman") +
  geom_node_point(aes(filter = leaf, x = x*1.07, y=y*1.07, colour=group, size=value, alpha=0.2)) +
  scale_colour_manual(values= colors4) +
  theme_void() +
  theme(legend.position="left", text=element_text(family="Times New Roman", size=10),
    plot.margin=unit(c(0,0,0,0),"cm")) +
  expand_limits(x = c(-1.8, 1.8), y = c(-1.8, 1.8))
print(p4)
```

Note: Previous graph has been created based-on code available in the site of [from data to viz](https://www.data-to-viz.com/graph/dendrogram.html).

## Query 5: What are the main interests of the UG researchers?

In this question, we try to identify the main topics in which UG authors research. To achieve this goal, papers' title were processed and we created a word cloud. 


```{r message= FALSE, wYesarning=FALSE}

query5 <- as.character(queries$V2[5])
qd5 <- SPARQL(endpoint, query5)
df5 <- qd5$results

# PREPROCESSING TEXT:
# Change words to singular:
pluw <- read.csv("pluralw.txt")
wordsToS <- names(pluw)
for (i in (1:length(wordsToS))){
  df5 <- data.frame(lapply(df5, function(x) {
                gsub(wordsToS[i], singularize(wordsToS[i]), x)}))
}

vectorDoc <- Corpus(VectorSource(df5$title))
vectorDoc = lemmatize_words(vectorDoc)
vectorDoc <- tm_map(vectorDoc, content_transformer(tolower)) 
vectorDoc <- tm_map(vectorDoc, content_transformer(removePunctuation))
vectorDoc <- tm_map(vectorDoc, content_transformer(removeNumbers)) 

# Remove stopwords from corpus
stopw <- read.csv("stopwords.txt")
stopw <- names(stopw)
stopwordsEN <- c(stopwords('english'))
stopwordsES <- c(stopwords('spanish'))
vectorDoc <- tm_map(vectorDoc, removeWords, stopwordsEN)
vectorDoc <- tm_map(vectorDoc, removeWords, stopw)
vectorDoc <- tm_map(vectorDoc, removeWords, stopwordsES)

# Creating matrix
myTdm <-  TermDocumentMatrix(vectorDoc) 
myTdm2 <- removeSparseTerms(myTdm, 0.999) 
myTdm3 <- rollup(myTdm2, 2, na.rm=TRUE, FUN = sum)

# Calculate the frequency of words and sort it descendingly by frequency
m2 <- as.matrix(myTdm3)
wordFreq <- sort(rowSums(m2), decreasing=TRUE)

# Visualization of word cloud
data = data.frame(names(wordFreq), freq=wordFreq)
wordcloud2(data[data$freq > 4 & data$freq < 80, ], color = '#1768AC') 

```

# References
